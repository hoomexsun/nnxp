{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953ba423",
   "metadata": {},
   "source": [
    "# Training - Usage Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50dc19c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-13 16:21:52,364 (xlit_task:132)  INFO: Data Information:\n",
      "2025-05-13 16:21:52,366 (xlit_task:133)  INFO: Batch size: 16\n",
      "2025-05-13 16:21:52,366 (xlit_task:134)  INFO: [Training] Data size: 44098 to 2757 batches\n",
      "2025-05-13 16:21:52,367 (xlit_task:137)  INFO: [Validation] Data size: 14699 to 919 batches\n",
      "2025-05-13 16:21:52,368 (xlit_task:140)  INFO: Token information\n",
      "2025-05-13 16:21:52,369 (xlit_task:141)  INFO: [ben] Tokenizer loaded with 64 tokens.\n",
      "2025-05-13 16:21:52,369 (xlit_task:144)  INFO: [mni] Tokenizer loaded with 47 tokens.\n",
      "2025-05-13 16:21:52,371 (xlit_task:150)  INFO: Model information:\n",
      "TransformerSeq2Seq(\n",
      "  (encoder_embed): Embedding(64, 256)\n",
      "  (decoder_embed): Embedding(47, 256)\n",
      "  (pos_encoder): PositionalEncoding()\n",
      "  (pos_decoder): PositionalEncoding()\n",
      "  (transformer): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-3): 4 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-3): 4 x TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=256, out_features=47, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "2025-05-13 16:21:52,372 (xlit_task:151)  INFO: Total trainable parameters: 5313071\n",
      "2025-05-13 16:21:52,373 (xlit_task:152)  INFO: Experiment directory: exp/xlit_train_transformer_char_ben_mni\n",
      "2025-05-13 16:21:52,373 (xlit_task:153)  INFO: Optimizer: Adam\n",
      "2025-05-13 16:21:52,374 (xlit_task:154)  INFO: Loss criterion: CrossEntropyLoss\n",
      "2025-05-13 16:21:52,375 (xlit_task:185)  INFO: Started training transformer model on [cuda]\n",
      "2025-05-13 16:21:52,375 (xlit_task:190)  INFO: Epoch 1/20\n",
      "2025-05-13 17:16:50,393 (xlit_task:200)  INFO: Train Loss: 0.1504\n",
      "2025-05-13 17:22:10,464 (xlit_task:227)  INFO: Saved best word accuracy predictions at epoch 1.\n",
      "2025-05-13 17:22:10,466 (xlit_task:238)  INFO: Val Loss: 0.0183, CER: 0.0540, Word Accuracy: 0.7516\n",
      "2025-05-13 17:22:10,467 (xlit_task:249)  INFO: Epoch 1 duration: 3618.09 sec | ETA: 19:05:43\n",
      "2025-05-13 17:22:10,535 (save:32)  INFO: Saved best training loss model at epoch 1.\n",
      "2025-05-13 17:22:10,567 (save:38)  INFO: Saved best validation loss model at epoch 1.\n",
      "2025-05-13 17:22:10,598 (save:44)  INFO: Saved best word accuracy model at epoch 1.\n",
      "2025-05-13 17:22:10,630 (save:48)  INFO: Saved latest model at epoch 1.\n",
      "2025-05-13 17:22:12,095 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-13 17:22:12,096 (xlit_task:190)  INFO: Epoch 2/20\n",
      "2025-05-13 18:17:21,283 (xlit_task:200)  INFO: Train Loss: 0.0269\n",
      "2025-05-13 18:22:45,402 (xlit_task:227)  INFO: Saved best word accuracy predictions at epoch 2.\n",
      "2025-05-13 18:22:45,403 (xlit_task:238)  INFO: Val Loss: 0.0100, CER: 0.0269, Word Accuracy: 0.8618\n",
      "2025-05-13 18:22:45,404 (xlit_task:249)  INFO: Epoch 2 duration: 3633.31 sec | ETA: 18:09:59\n",
      "2025-05-13 18:22:45,500 (save:32)  INFO: Saved best training loss model at epoch 2.\n",
      "2025-05-13 18:22:45,681 (save:38)  INFO: Saved best validation loss model at epoch 2.\n",
      "2025-05-13 18:22:45,838 (save:44)  INFO: Saved best word accuracy model at epoch 2.\n",
      "2025-05-13 18:22:45,915 (save:48)  INFO: Saved latest model at epoch 2.\n",
      "2025-05-13 18:22:47,093 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-13 18:22:47,094 (xlit_task:190)  INFO: Epoch 3/20\n",
      "2025-05-13 19:17:30,523 (xlit_task:200)  INFO: Train Loss: 0.0168\n",
      "2025-05-13 19:22:51,844 (xlit_task:227)  INFO: Saved best word accuracy predictions at epoch 3.\n",
      "2025-05-13 19:22:51,845 (xlit_task:238)  INFO: Val Loss: 0.0077, CER: 0.0195, Word Accuracy: 0.8977\n",
      "2025-05-13 19:22:51,847 (xlit_task:249)  INFO: Epoch 3 duration: 3604.75 sec | ETA: 17:01:20\n",
      "2025-05-13 19:22:51,948 (save:32)  INFO: Saved best training loss model at epoch 3.\n",
      "2025-05-13 19:22:52,048 (save:38)  INFO: Saved best validation loss model at epoch 3.\n",
      "2025-05-13 19:22:52,158 (save:44)  INFO: Saved best word accuracy model at epoch 3.\n",
      "2025-05-13 19:22:52,270 (save:48)  INFO: Saved latest model at epoch 3.\n",
      "2025-05-13 19:22:53,521 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-13 19:22:53,522 (xlit_task:190)  INFO: Epoch 4/20\n",
      "2025-05-13 20:18:08,314 (xlit_task:200)  INFO: Train Loss: 0.0131\n",
      "2025-05-13 20:23:37,286 (xlit_task:227)  INFO: Saved best word accuracy predictions at epoch 4.\n",
      "2025-05-13 20:23:37,288 (xlit_task:238)  INFO: Val Loss: 0.0074, CER: 0.0172, Word Accuracy: 0.9070\n",
      "2025-05-13 20:23:37,289 (xlit_task:249)  INFO: Epoch 4 duration: 3643.77 sec | ETA: 16:11:40\n",
      "2025-05-13 20:23:37,380 (save:32)  INFO: Saved best training loss model at epoch 4.\n",
      "2025-05-13 20:23:37,470 (save:38)  INFO: Saved best validation loss model at epoch 4.\n",
      "2025-05-13 20:23:37,588 (save:44)  INFO: Saved best word accuracy model at epoch 4.\n",
      "2025-05-13 20:23:37,775 (save:48)  INFO: Saved latest model at epoch 4.\n",
      "2025-05-13 20:23:39,053 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-13 20:23:39,055 (xlit_task:190)  INFO: Epoch 5/20\n",
      "2025-05-13 21:18:30,053 (xlit_task:200)  INFO: Train Loss: 0.0108\n",
      "2025-05-13 21:23:50,499 (xlit_task:227)  INFO: Saved best word accuracy predictions at epoch 5.\n",
      "2025-05-13 21:23:50,500 (xlit_task:238)  INFO: Val Loss: 0.0054, CER: 0.0134, Word Accuracy: 0.9257\n",
      "2025-05-13 21:23:50,501 (xlit_task:249)  INFO: Epoch 5 duration: 3611.45 sec | ETA: 15:02:51\n",
      "2025-05-13 21:23:50,605 (save:32)  INFO: Saved best training loss model at epoch 5.\n",
      "2025-05-13 21:23:50,691 (save:38)  INFO: Saved best validation loss model at epoch 5.\n",
      "2025-05-13 21:23:50,805 (save:44)  INFO: Saved best word accuracy model at epoch 5.\n",
      "2025-05-13 21:23:50,992 (save:48)  INFO: Saved latest model at epoch 5.\n",
      "2025-05-13 21:23:52,304 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-13 21:23:52,305 (xlit_task:190)  INFO: Epoch 6/20\n",
      "2025-05-13 22:18:39,641 (xlit_task:200)  INFO: Train Loss: 0.0095\n",
      "2025-05-13 22:24:01,041 (xlit_task:227)  INFO: Saved best word accuracy predictions at epoch 6.\n",
      "2025-05-13 22:24:01,042 (xlit_task:238)  INFO: Val Loss: 0.0052, CER: 0.0123, Word Accuracy: 0.9309\n",
      "2025-05-13 22:24:01,044 (xlit_task:249)  INFO: Epoch 6 duration: 3608.74 sec | ETA: 14:02:02\n",
      "2025-05-13 22:24:01,149 (save:32)  INFO: Saved best training loss model at epoch 6.\n",
      "2025-05-13 22:24:01,244 (save:38)  INFO: Saved best validation loss model at epoch 6.\n",
      "2025-05-13 22:24:01,359 (save:44)  INFO: Saved best word accuracy model at epoch 6.\n",
      "2025-05-13 22:24:01,477 (save:48)  INFO: Saved latest model at epoch 6.\n",
      "2025-05-13 22:24:01,504 (save:73)  INFO: Removed evicted model from epoch 1.\n",
      "2025-05-13 22:24:02,720 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-13 22:24:02,721 (xlit_task:190)  INFO: Epoch 7/20\n",
      "2025-05-13 23:18:38,218 (xlit_task:200)  INFO: Train Loss: 0.0083\n",
      "2025-05-13 23:24:04,473 (xlit_task:227)  INFO: Saved best word accuracy predictions at epoch 7.\n",
      "2025-05-13 23:24:04,474 (xlit_task:238)  INFO: Val Loss: 0.0054, CER: 0.0120, Word Accuracy: 0.9333\n",
      "2025-05-13 23:24:04,475 (xlit_task:249)  INFO: Epoch 7 duration: 3601.75 sec | ETA: 13:00:22\n",
      "2025-05-13 23:24:04,580 (save:32)  INFO: Saved best training loss model at epoch 7.\n",
      "2025-05-13 23:24:04,665 (save:44)  INFO: Saved best word accuracy model at epoch 7.\n",
      "2025-05-13 23:24:04,787 (save:48)  INFO: Saved latest model at epoch 7.\n",
      "2025-05-13 23:24:04,813 (save:73)  INFO: Removed evicted model from epoch 2.\n",
      "2025-05-13 23:24:06,056 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-13 23:24:06,057 (xlit_task:190)  INFO: Epoch 8/20\n",
      "2025-05-14 00:19:01,397 (xlit_task:200)  INFO: Train Loss: 0.0076\n",
      "2025-05-14 00:24:25,376 (xlit_task:227)  INFO: Saved best word accuracy predictions at epoch 8.\n",
      "2025-05-14 00:24:25,377 (xlit_task:238)  INFO: Val Loss: 0.0048, CER: 0.0109, Word Accuracy: 0.9375\n",
      "2025-05-14 00:24:25,378 (xlit_task:249)  INFO: Epoch 8 duration: 3619.32 sec | ETA: 12:03:51\n",
      "2025-05-14 00:24:25,481 (save:32)  INFO: Saved best training loss model at epoch 8.\n",
      "2025-05-14 00:24:25,573 (save:38)  INFO: Saved best validation loss model at epoch 8.\n",
      "2025-05-14 00:24:25,689 (save:44)  INFO: Saved best word accuracy model at epoch 8.\n",
      "2025-05-14 00:24:25,812 (save:48)  INFO: Saved latest model at epoch 8.\n",
      "2025-05-14 00:24:25,837 (save:73)  INFO: Removed evicted model from epoch 3.\n",
      "2025-05-14 00:24:27,092 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-14 00:24:27,093 (xlit_task:190)  INFO: Epoch 9/20\n",
      "2025-05-14 01:19:20,343 (xlit_task:200)  INFO: Train Loss: 0.0069\n",
      "2025-05-14 01:24:45,896 (xlit_task:238)  INFO: Val Loss: 0.0044, CER: 0.0110, Word Accuracy: 0.9363\n",
      "2025-05-14 01:24:45,897 (xlit_task:249)  INFO: Epoch 9 duration: 3618.80 sec | ETA: 11:03:26\n",
      "2025-05-14 01:24:45,998 (save:32)  INFO: Saved best training loss model at epoch 9.\n",
      "2025-05-14 01:24:46,101 (save:38)  INFO: Saved best validation loss model at epoch 9.\n",
      "2025-05-14 01:24:46,313 (save:48)  INFO: Saved latest model at epoch 9.\n",
      "2025-05-14 01:24:46,339 (save:73)  INFO: Removed evicted model from epoch 4.\n",
      "2025-05-14 01:24:47,607 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-14 01:24:47,608 (xlit_task:190)  INFO: Epoch 10/20\n",
      "2025-05-14 02:19:42,704 (xlit_task:200)  INFO: Train Loss: 0.0063\n",
      "2025-05-14 02:25:06,354 (xlit_task:227)  INFO: Saved best word accuracy predictions at epoch 10.\n",
      "2025-05-14 02:25:06,355 (xlit_task:238)  INFO: Val Loss: 0.0042, CER: 0.0099, Word Accuracy: 0.9424\n",
      "2025-05-14 02:25:06,356 (xlit_task:249)  INFO: Epoch 10 duration: 3618.75 sec | ETA: 10:03:07\n",
      "2025-05-14 02:25:06,454 (save:32)  INFO: Saved best training loss model at epoch 10.\n",
      "2025-05-14 02:25:06,615 (save:38)  INFO: Saved best validation loss model at epoch 10.\n",
      "2025-05-14 02:25:06,697 (save:44)  INFO: Saved best word accuracy model at epoch 10.\n",
      "2025-05-14 02:25:06,820 (save:48)  INFO: Saved latest model at epoch 10.\n",
      "2025-05-14 02:25:06,847 (save:73)  INFO: Removed evicted model from epoch 7.\n",
      "2025-05-14 02:25:08,062 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-14 02:25:08,063 (xlit_task:190)  INFO: Epoch 11/20\n",
      "2025-05-14 03:20:04,867 (xlit_task:200)  INFO: Train Loss: 0.0061\n",
      "2025-05-14 03:25:26,752 (xlit_task:227)  INFO: Saved best word accuracy predictions at epoch 11.\n",
      "2025-05-14 03:25:26,753 (xlit_task:238)  INFO: Val Loss: 0.0039, CER: 0.0095, Word Accuracy: 0.9456\n",
      "2025-05-14 03:25:26,755 (xlit_task:249)  INFO: Epoch 11 duration: 3618.69 sec | ETA: 09:02:48\n",
      "2025-05-14 03:25:26,858 (save:32)  INFO: Saved best training loss model at epoch 11.\n",
      "2025-05-14 03:25:26,980 (save:38)  INFO: Saved best validation loss model at epoch 11.\n",
      "2025-05-14 03:25:27,144 (save:44)  INFO: Saved best word accuracy model at epoch 11.\n",
      "2025-05-14 03:25:27,253 (save:48)  INFO: Saved latest model at epoch 11.\n",
      "2025-05-14 03:25:27,282 (save:73)  INFO: Removed evicted model from epoch 5.\n",
      "2025-05-14 03:25:28,510 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-14 03:25:28,511 (xlit_task:190)  INFO: Epoch 12/20\n",
      "2025-05-14 04:20:34,020 (xlit_task:200)  INFO: Train Loss: 0.0056\n",
      "2025-05-14 04:26:00,077 (xlit_task:227)  INFO: Saved best word accuracy predictions at epoch 12.\n",
      "2025-05-14 04:26:00,078 (xlit_task:238)  INFO: Val Loss: 0.0040, CER: 0.0092, Word Accuracy: 0.9472\n",
      "2025-05-14 04:26:00,080 (xlit_task:249)  INFO: Epoch 12 duration: 3631.57 sec | ETA: 08:04:12\n",
      "2025-05-14 04:26:00,179 (save:32)  INFO: Saved best training loss model at epoch 12.\n",
      "2025-05-14 04:26:00,312 (save:44)  INFO: Saved best word accuracy model at epoch 12.\n",
      "2025-05-14 04:26:00,454 (save:48)  INFO: Saved latest model at epoch 12.\n",
      "2025-05-14 04:26:00,481 (save:73)  INFO: Removed evicted model from epoch 6.\n",
      "2025-05-14 04:26:01,711 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-14 04:26:01,712 (xlit_task:190)  INFO: Epoch 13/20\n",
      "2025-05-14 05:20:56,586 (xlit_task:200)  INFO: Train Loss: 0.0055\n",
      "2025-05-14 05:26:19,542 (xlit_task:238)  INFO: Val Loss: 0.0050, CER: 0.0111, Word Accuracy: 0.9359\n",
      "2025-05-14 05:26:19,543 (xlit_task:249)  INFO: Epoch 13 duration: 3617.83 sec | ETA: 07:02:04\n",
      "2025-05-14 05:26:19,648 (save:32)  INFO: Saved best training loss model at epoch 13.\n",
      "2025-05-14 05:26:19,762 (save:48)  INFO: Saved latest model at epoch 13.\n",
      "2025-05-14 05:26:20,988 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-14 05:26:20,990 (xlit_task:190)  INFO: Epoch 14/20\n",
      "2025-05-14 06:21:13,503 (xlit_task:200)  INFO: Train Loss: 0.0052\n",
      "2025-05-14 06:26:36,774 (xlit_task:227)  INFO: Saved best word accuracy predictions at epoch 14.\n",
      "2025-05-14 06:26:36,775 (xlit_task:238)  INFO: Val Loss: 0.0042, CER: 0.0089, Word Accuracy: 0.9487\n",
      "2025-05-14 06:26:36,777 (xlit_task:249)  INFO: Epoch 14 duration: 3615.79 sec | ETA: 06:01:34\n",
      "2025-05-14 06:26:36,924 (save:32)  INFO: Saved best training loss model at epoch 14.\n",
      "2025-05-14 06:26:37,017 (save:44)  INFO: Saved best word accuracy model at epoch 14.\n",
      "2025-05-14 06:26:37,131 (save:48)  INFO: Saved latest model at epoch 14.\n",
      "2025-05-14 06:26:37,156 (save:73)  INFO: Removed evicted model from epoch 8.\n",
      "2025-05-14 06:26:38,401 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-14 06:26:38,402 (xlit_task:190)  INFO: Epoch 15/20\n",
      "2025-05-14 07:21:39,167 (xlit_task:200)  INFO: Train Loss: 0.0049\n",
      "2025-05-14 07:26:59,864 (xlit_task:227)  INFO: Saved best word accuracy predictions at epoch 15.\n",
      "2025-05-14 07:26:59,865 (xlit_task:238)  INFO: Val Loss: 0.0039, CER: 0.0083, Word Accuracy: 0.9509\n",
      "2025-05-14 07:26:59,867 (xlit_task:249)  INFO: Epoch 15 duration: 3621.46 sec | ETA: 05:01:47\n",
      "2025-05-14 07:26:59,962 (save:32)  INFO: Saved best training loss model at epoch 15.\n",
      "2025-05-14 07:27:00,082 (save:38)  INFO: Saved best validation loss model at epoch 15.\n",
      "2025-05-14 07:27:00,187 (save:44)  INFO: Saved best word accuracy model at epoch 15.\n",
      "2025-05-14 07:27:00,326 (save:48)  INFO: Saved latest model at epoch 15.\n",
      "2025-05-14 07:27:00,353 (save:73)  INFO: Removed evicted model from epoch 9.\n",
      "2025-05-14 07:27:01,608 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-14 07:27:01,609 (xlit_task:190)  INFO: Epoch 16/20\n",
      "2025-05-14 08:22:11,773 (xlit_task:200)  INFO: Train Loss: 0.0049\n",
      "2025-05-14 08:27:35,371 (xlit_task:238)  INFO: Val Loss: 0.0042, CER: 0.0092, Word Accuracy: 0.9472\n",
      "2025-05-14 08:27:35,373 (xlit_task:249)  INFO: Epoch 16 duration: 3633.76 sec | ETA: 04:02:15\n",
      "2025-05-14 08:27:35,486 (save:32)  INFO: Saved best training loss model at epoch 16.\n",
      "2025-05-14 08:27:35,576 (save:48)  INFO: Saved latest model at epoch 16.\n",
      "2025-05-14 08:27:35,602 (save:73)  INFO: Removed evicted model from epoch 14.\n",
      "2025-05-14 08:27:36,866 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-14 08:27:36,868 (xlit_task:190)  INFO: Epoch 17/20\n",
      "2025-05-14 09:21:54,582 (xlit_task:200)  INFO: Train Loss: 0.0047\n",
      "2025-05-14 09:27:15,116 (xlit_task:227)  INFO: Saved best word accuracy predictions at epoch 17.\n",
      "2025-05-14 09:27:15,117 (xlit_task:238)  INFO: Val Loss: 0.0035, CER: 0.0082, Word Accuracy: 0.9526\n",
      "2025-05-14 09:27:15,118 (xlit_task:249)  INFO: Epoch 17 duration: 3578.25 sec | ETA: 02:58:54\n",
      "2025-05-14 09:27:15,211 (save:32)  INFO: Saved best training loss model at epoch 17.\n",
      "2025-05-14 09:27:15,320 (save:38)  INFO: Saved best validation loss model at epoch 17.\n",
      "2025-05-14 09:27:15,464 (save:44)  INFO: Saved best word accuracy model at epoch 17.\n",
      "2025-05-14 09:27:15,549 (save:48)  INFO: Saved latest model at epoch 17.\n",
      "2025-05-14 09:27:15,575 (save:73)  INFO: Removed evicted model from epoch 10.\n",
      "2025-05-14 09:27:16,843 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-14 09:27:16,844 (xlit_task:190)  INFO: Epoch 18/20\n",
      "2025-05-14 10:21:36,207 (xlit_task:200)  INFO: Train Loss: 0.0046\n",
      "2025-05-14 10:26:55,729 (xlit_task:238)  INFO: Val Loss: 0.0036, CER: 0.0084, Word Accuracy: 0.9505\n",
      "2025-05-14 10:26:55,731 (xlit_task:249)  INFO: Epoch 18 duration: 3578.89 sec | ETA: 01:59:17\n",
      "2025-05-14 10:26:55,850 (save:32)  INFO: Saved best training loss model at epoch 18.\n",
      "2025-05-14 10:26:55,944 (save:48)  INFO: Saved latest model at epoch 18.\n",
      "2025-05-14 10:26:55,969 (save:73)  INFO: Removed evicted model from epoch 16.\n",
      "2025-05-14 10:26:57,229 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-14 10:26:57,230 (xlit_task:190)  INFO: Epoch 19/20\n",
      "2025-05-14 11:21:22,291 (xlit_task:200)  INFO: Train Loss: 0.0042\n",
      "2025-05-14 11:26:41,962 (xlit_task:227)  INFO: Saved best word accuracy predictions at epoch 19.\n",
      "2025-05-14 11:26:41,963 (xlit_task:238)  INFO: Val Loss: 0.0036, CER: 0.0080, Word Accuracy: 0.9534\n",
      "2025-05-14 11:26:41,964 (xlit_task:249)  INFO: Epoch 19 duration: 3584.73 sec | ETA: 00:59:44\n",
      "2025-05-14 11:26:42,069 (save:32)  INFO: Saved best training loss model at epoch 19.\n",
      "2025-05-14 11:26:42,185 (save:44)  INFO: Saved best word accuracy model at epoch 19.\n",
      "2025-05-14 11:26:42,261 (save:48)  INFO: Saved latest model at epoch 19.\n",
      "2025-05-14 11:26:42,287 (save:73)  INFO: Removed evicted model from epoch 12.\n",
      "2025-05-14 11:26:43,546 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-14 11:26:43,547 (xlit_task:190)  INFO: Epoch 20/20\n",
      "2025-05-14 12:21:54,638 (xlit_task:200)  INFO: Train Loss: 0.0042\n",
      "2025-05-14 12:27:40,427 (xlit_task:238)  INFO: Val Loss: 0.0041, CER: 0.0085, Word Accuracy: 0.9520\n",
      "2025-05-14 12:27:40,429 (xlit_task:249)  INFO: Epoch 20 duration: 3656.88 sec | ETA: 00:00:00\n",
      "2025-05-14 12:27:40,556 (save:32)  INFO: Saved best training loss model at epoch 20.\n",
      "2025-05-14 12:27:40,680 (save:48)  INFO: Saved latest model at epoch 20.\n",
      "2025-05-14 12:27:40,991 (save:84)  INFO: Saved averaged model at the end of training.\n",
      "2025-05-14 12:27:42,248 (xlit_task:274)  INFO: Saved [loss, wa, cer] curves at exp/xlit_train_transformer_char_ben_mni/images\n",
      "2025-05-14 12:27:42,250 (xlit_task:283)  INFO: Training completed in 1205:00:50\n"
     ]
    }
   ],
   "source": [
    "from src.xlit_task import XlitTask\n",
    "\n",
    "conf_file = \"tuning/transformer.yaml\"\n",
    "task = XlitTask(conf_file)\n",
    "task.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
